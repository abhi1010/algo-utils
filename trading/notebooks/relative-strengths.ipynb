{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "import subprocess\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "DIR = '/tmp/p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAR_DATE = datetime.datetime(2021, 7, 20)\n",
    "NEAR_DATE = datetime.datetime(2021, 9, 21)\n",
    "\n",
    "def find_days_since_near_far(far_date, near_date):\n",
    "    now = datetime.datetime.now()\n",
    "    days_since_far_date = (now - far_date).days\n",
    "    days_since_near_date = (now - near_date).days\n",
    "    return days_since_far_date, days_since_near_date\n",
    "\n",
    "\n",
    "FAR_DAYS, NEAR_DAYS = find_days_since_near_far(FAR_DATE, NEAR_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_cmd(cmds):\n",
    "    print(f'cmds = {cmds}')\n",
    "    proc = subprocess.Popen(\n",
    "        cmds,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "    )\n",
    "    stdout, stderr = proc.communicate(timeout=1000)\n",
    "    if stderr:\n",
    "        stderr_s = stderr.decode('utf-8').split('\\n')\n",
    "        for s in stderr_s:\n",
    "            print(f'stderr = {s}')\n",
    "    return stdout.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_kucoin_pairs():\n",
    "    cmds = 've/bin/freqtrade list-markets --exchange kucoin --userdir freqtrade/user_data --quote USDT -1'.split(\n",
    "        ' ')\n",
    "    res = run_cmd(cmds).split('\\n')\n",
    "    return [\n",
    "        r for r in res\n",
    "        if r and not r.endswith('3L/USDT') and not r.endswith('3S/USDT')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_json_files(dir_path):\n",
    "    return [\n",
    "        os.path.join(dir_path, f)\n",
    "        for f in os.listdir(dir_path)\n",
    "        if f.endswith('.json')\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(json_file):\n",
    "    with open(json_file, 'rt') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['ts', 'open', 'high', 'low', 'close', 'volume']\n",
    "    # df['date'] = df.ts.apply(lambda d: datetime.datetime.fromtimestamp(int(d)).strftime('%Y-%m-%d'))\n",
    "    df['date'] = pd.to_datetime(df.ts, unit='ms')\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_file_data(json_files):\n",
    "    all_data = dict()\n",
    "    for json_file in json_files:\n",
    "        json_pd = read_json_file(json_file)\n",
    "        token_name = json_file.split('/')[-1].split('.')[0]\n",
    "        usdt_idx = token_name.find('_USDT')\n",
    "        token_name_simplified = token_name[:usdt_idx]\n",
    "        all_data[token_name_simplified] = json_pd\n",
    "        print(f'token_name={token_name_simplified}; json_file={json_file}; json_pd = {json_pd}')\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_relative_strength(token_name,df, btc_data, ref_date = FAR_DATE, rs_type_name='far', btc_ref='btc_far_ref'):\n",
    "    # df['simple_rs']=  df['close'] / btc_data['close']\n",
    "    first_date = df.date.min()\n",
    "    if first_date > FAR_DATE:\n",
    "        print(f'<{token_name}> first_date = {first_date}. Just released. Moving on')\n",
    "        return None\n",
    "    price_on_date = lambda d: d.loc[d['date'] == ref_date].iloc[0]['close']\n",
    "    token_close_price_on_far_ref_date = price_on_date(df)\n",
    "    btc_close_price_on_far_ref_date = price_on_date(btc_data)\n",
    "    print(f'price_on_{ref_date} = {token_close_price_on_far_ref_date}; btc_close_price_on_far_ref_date={btc_close_price_on_far_ref_date}')\n",
    "    df[rs_type_name] = df['close'] / token_close_price_on_far_ref_date\n",
    "    df[btc_ref]  = btc_data['close'] / btc_close_price_on_far_ref_date\n",
    "    df[rs_type_name + '_rs'] = df[rs_type_name] / df[btc_ref] - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Yield successive n-sized\n",
    "# chunks from l.\n",
    "def divide_chunks(l, n):\n",
    "\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def download_data(kucoin_pairs):\n",
    "    split_pairs = list(divide_chunks(kucoin_pairs, 50))\n",
    "    for pairs_list in split_pairs:\n",
    "        with open('/tmp/tmp-pairs.json', 'wt') as tmp_pairs_file:\n",
    "            tmp_pairs_file.write(json.dumps(pairs_list))\n",
    "\n",
    "        cmds = f'freqtrade download-data --exchange kucoin --userdir freqtrade/user_data --pairs-file /tmp/tmp-pairs.json --exchange kucoin --days {FAR_DAYS+20} -t 1d -d /tmp/p'.split(\n",
    "            ' ')\n",
    "        res = run_cmd(cmds)\n",
    "        print(f'Downloading data for : {pairs_list}. \\n\\n res = {res}')\n",
    "        print('Sleeping for 10 seconds')\n",
    "        time.sleep(10)\n",
    "        # print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_strengths(pairs_to_use, btc_token_name):\n",
    "    json_files = get_json_files(DIR)\n",
    "\n",
    "    # print(f'json_files = {json_files}')\n",
    "    find_json_file = lambda token: [j for j in json_files if token.replace('/', '_') in j][0]\n",
    "    btc_json_file = find_json_file(btc_token_name)\n",
    "    print(f'btc_json_file = {btc_json_file}')\n",
    "    btc_json_data = read_json_file(btc_json_file)\n",
    "    tokens_with_positive_far_rs = []\n",
    "    tokens_with_positive_near_rs = []\n",
    "    highlighted_tokens_with_positive_rs = []\n",
    "    for token in pairs_to_use:\n",
    "        if btc_token_name in token:\n",
    "            continue\n",
    "        print(f'token = {token}')\n",
    "        token_json_file = find_json_file(token)\n",
    "        print(f'  token_json_file = {token_json_file}')\n",
    "        token_df = read_json_file(token_json_file)\n",
    "        create_simple_relative_strength(token, token_df, btc_json_data, FAR_DATE,  rs_type_name='far', btc_ref='btc_far_ref')\n",
    "        create_simple_relative_strength(token, token_df, btc_json_data, NEAR_DATE,  rs_type_name='near', btc_ref='btc_near_ref')\n",
    "        last_row_far_rs = token_df.iloc[-1]['far_rs'] if 'far_rs' in token_df.columns else None\n",
    "        last_row_near_rs = token_df.iloc[-1]['near_rs'] if 'near_rs' in token_df.columns else None\n",
    "\n",
    "        first_date = token_df.date.min()\n",
    "        if first_date <= FAR_DATE and last_row_far_rs is not None  and last_row_far_rs > 0 and last_row_near_rs > last_row_far_rs:\n",
    "            token_df['highlight'] = 1\n",
    "        else:\n",
    "            token_df['highlight'] = 0\n",
    "\n",
    "\n",
    "        last_row_highlight = token_df.iloc[-1]['highlight'] if 'highlight' in token_df.columns else None\n",
    "        print(f'<{token}>: Far RS: {last_row_far_rs}; Near RS: {last_row_near_rs}; highlight: {last_row_highlight}')\n",
    "        highlighted_tokens_with_positive_rs.append(token) if last_row_highlight == 1 else None\n",
    "\n",
    "        if last_row_far_rs is not None and last_row_far_rs > 0:\n",
    "            tokens_with_positive_far_rs.append(token)\n",
    "            # print(f'<{token}>:  last_row_far_rs = {last_row_far_rs}')\n",
    "            # print(f'<{token}>:  last_row_far_rs = {last_row_far_rs}')\n",
    "        if last_row_near_rs is not None and last_row_near_rs > 0:\n",
    "            tokens_with_positive_near_rs.append(token)\n",
    "            # print(f'<{token}>:  last_row_near_rs = {last_row_near_rs}')\n",
    "        # else:\n",
    "        #     print(f'<{token}>:  last_row_near_rs = {last_row_near_rs}')\n",
    "\n",
    "    return tokens_with_positive_far_rs, tokens_with_positive_near_rs, highlighted_tokens_with_positive_rs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(should_download_pairs, should_download_data, should_calculate_relative_strength, debug):\n",
    "    btc_token_name = 'BTC/USDT'\n",
    "    # print(f'split_pairs = {split_pairs}; len = {len(split_pairs)}')\n",
    "    if should_download_pairs:\n",
    "        kucoin_pairs = get_kucoin_pairs()\n",
    "        if debug:\n",
    "            pairs_to_use = kucoin_pairs[:2] + [btc_token_name]\n",
    "        else:\n",
    "            pairs_to_use = kucoin_pairs\n",
    "    else:\n",
    "        pairs_to_use = ['1EARTH/USDT', '1INCH/USDT' , btc_token_name]\n",
    "    print(f'kucoin_pairs = {pairs_to_use}')\n",
    "    if should_download_data:\n",
    "        print(f'Downloading data for: {pairs_to_use}')\n",
    "        download_data(pairs_to_use)\n",
    "\n",
    "\n",
    "    if should_calculate_relative_strength:\n",
    "        tokens_with_positive_far_rs, tokens_with_positive_near_rs, highlighted_tokens_with_positive_rs = check_relative_strengths(pairs_to_use, btc_token_name)\n",
    "        print(f'Tokens with positive relative strength FAR: {tokens_with_positive_far_rs}')\n",
    "        print(f'Tokens with positive relative strength NEAR: {tokens_with_positive_near_rs}')\n",
    "        print(f'highlighted_tokens_with_positive_rs = {highlighted_tokens_with_positive_rs}\\n')\n",
    "        tradingview_style = ','.join(['KUCOIN:' + x.replace('/', '') for x in highlighted_tokens_with_positive_rs])\n",
    "        print(f'\\nTokens with positive relative strength: {tradingview_style}\\n')\n",
    "        print(f'FAR_DAYS, NEAR_DAYS = {FAR_DAYS}, {NEAR_DAYS}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main(should_download_pairs=True, should_download_data=False, should_calculate_relative_strength=True,  debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcd48d41fde0f35dc0abc5878b02d05fd876be7b411dba991a956d2a3c7e74c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
